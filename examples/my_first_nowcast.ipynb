{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_dntwSQBnbK"
   },
   "source": [
    "# My first precipitation nowcast\n",
    "\n",
    "Here we will use pysteps to compute and plot an extrapolation nowcast using the NSSL's Multi-Radar/Multi-Sensor System\n",
    "([MRMS](https://www.nssl.noaa.gov/projects/mrms/)) rain rate product.\n",
    "\n",
    "The MRMS precipitation product is available every 2 minutes, over the contiguous US. \n",
    "Each precipitation composite has 3500 x 7000 grid points, separated 1 km from each other.\n",
    "\n",
    "## Set-up Colab environment\n",
    "\n",
    "**Important**: In colab, execute this section one cell at a time. Trying to excecute all the cells at once may results in cells being skipped and some dependencies not being installed.\n",
    "\n",
    "First, let's set up our working environment. Note that these steps are only needed to work with google colab. \n",
    "\n",
    "To install pysteps locally, you can follow [these instructions](https://pysteps.readthedocs.io/en/latest/user_guide/install_pysteps.html).\n",
    "\n",
    "First, let's install the latest Pysteps version from the Python Package Index (PyPI) using pip. This will also install the minimal dependencies needed to run pysteps. \n",
    "\n",
    "#### Install optional dependencies\n",
    "\n",
    "Now, let's install the optional dependendies that will allow us to plot and read the example data.\n",
    "- pygrib: to read the MRMS data grib format\n",
    "- pyproj: needed by pygrib\n",
    "\n",
    "**NOTE:** Do not import pysteps in this notebook until the following optional dependencies are loaded. Otherwise, pysteps will assume that they are not installed and some of the pystps functionalities won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFx4hq_DBtp-"
   },
   "outputs": [],
   "source": [
    "# This libraries are needed for the pygrib library. \n",
    "# Note that is needed if you install pygrib using pip. \n",
    "# If you use conda, the libraries will be installed automatically.\n",
    "! apt-get install libeccodes-dev libproj-dev\n",
    "! pip install pyproj\n",
    "! pip install pygrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BF2paxnTuGB"
   },
   "outputs": [],
   "source": [
    "# Uninstall existing shapely\n",
    "!pip uninstall --yes shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7x8Hx_4hE_BU"
   },
   "outputs": [],
   "source": [
    "# To install cartopy in Colab using pip, we need to install the library \n",
    "# dependencies first.\n",
    "\n",
    "!apt-get install -qq libgdal-dev libgeos-dev\n",
    "!pip install shapely --no-binary shapely\n",
    "!pip install cartopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybD55ZJhmdYa"
   },
   "source": [
    "#### Install pysteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VA7zp3nRmhfF"
   },
   "outputs": [],
   "source": [
    "# ! pip install pysteps\n",
    "! pip install git+https://github.com/pySTEPS/pysteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AkfR6JSBujn"
   },
   "source": [
    "## Getting the example data\n",
    "\n",
    "Now that we have the environment ready, let's install the example data and configure the pysteps's default parameters by following [this tutorial](https://pysteps.readthedocs.io/en/latest/user_guide/example_data.html).\n",
    "\n",
    "First, we will use the [pysteps.datasets.download_pysteps_data()](https://pysteps.readthedocs.io/en/latest/generated/pysteps.datasets.download_pysteps_data.html) function to download the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vri-R_ZVGihj"
   },
   "outputs": [],
   "source": [
    "# Import the helper functions\n",
    "from pysteps.datasets import download_pysteps_data, create_default_pystepsrc\n",
    "\n",
    "# Download the pysteps data in the \"pysteps_data\"\n",
    "download_pysteps_data(\"pysteps_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdKfjliCKXhx"
   },
   "source": [
    "Now we need to create a default configuration file that points to the downloaded data. By default pysteps will place the configuration file in `$HOME/.pysteps` (unix and Mac OS X) or `$USERPROFILE/pysteps` (windows).\n",
    "To quickly create a configuration file, we will use the [pysteps.datasets.create_default_pystepsrc()](https://pysteps.readthedocs.io/en/latest/generated/pysteps.datasets.create_default_pystepsrc.html#pysteps.datasets.create_default_pystepsrc) helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGdKHa36H5JX"
   },
   "outputs": [],
   "source": [
    "# If the configuration file is placed in one of the default locations \n",
    "# (https://pysteps.readthedocs.io/en/latest/user_guide/set_pystepsrc.html#configuration-file-lookup) \n",
    "# it will be loaded automatically when pysteps is importer. \n",
    "config_file_path = create_default_pystepsrc(\"pysteps_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAFUJgR5K1CS"
   },
   "source": [
    "And since in this notebook pysteps was already initialized,\n",
    "we need to load the new configuration file and \n",
    "update the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMIbQLPAK42h"
   },
   "outputs": [],
   "source": [
    "import pysteps\n",
    "_ = pysteps.load_config_file(config_file_path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzSqp1DFJ0M9"
   },
   "source": [
    "Let's see how the default parameters look like (these are stored in the\n",
    "[pystepsrc file](https://pysteps.readthedocs.io/en/latest/user_guide/set_pystepsrc.html)). We will be using them to load the MRMS data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Gr65nH4BnbP"
   },
   "outputs": [],
   "source": [
    "# The default parameters are stored in pysteps.rcparams.\n",
    "from pprint import pprint\n",
    "pprint(pysteps.rcparams.data_sources['mrms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9M_buv7WBnbf"
   },
   "source": [
    "Note that the default `timestep` parameter is 2 minutes, which corresponds to the time interval at which the MRMS product is available.\n",
    "\n",
    "## Load the MRMS example data\n",
    "\n",
    "Now that we have installed the example data, let's import the example MRMS dataset using the [load_dataset()](https://pysteps.readthedocs.io/en/latest/generated/pysteps.datasets.load_dataset.html) helper function from the `pysteps.datasets` module.\n",
    "\n",
    "We import 1 hour and 10 minutes of data, which corresponds to a sequence of 36 frames of 2-D precipitation composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8Q4e58VBnbl"
   },
   "outputs": [],
   "source": [
    "from pysteps.datasets import load_dataset\n",
    "\n",
    "precipitation, metadata, timestep = load_dataset('mrms',frames=35)  # precipitation in mm/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btiTxYYMBnby"
   },
   "source": [
    "Let's have a look at the values returned by the `load_dataset()` function. \n",
    "\n",
    "- `precipitation`: A numpy array with (time, latitude, longitude) dimensions.\n",
    "- `metadata`: A dictionary with additional information (pixel sizes, map projections, etc.).\n",
    "- `timestep`: Time separation between each sample (in minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqUHbJ_qBnb3"
   },
   "outputs": [],
   "source": [
    "precipitation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xa8woT0ABncD"
   },
   "source": [
    "Note that the shape of the precipitation is 4 times smaller than the raw MRMS data (3500 x 7000).\n",
    "The `load_dataset()` function uses the default parameters for the `importers` used to read the data and by default the MRMS importer upscales the data 4x, that is, from ~1k resolution to ~4km. It also uses single precision to reduce the memory requirements.\n",
    "Thanks to the upscaling, the memory footprint of this example dataset is ~200Mb instead of the 3.1Gb of the raw (3500 x 7000) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22O2YXrfBncG"
   },
   "outputs": [],
   "source": [
    "timestep # In minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8_4hwcXBncT"
   },
   "outputs": [],
   "source": [
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQREORtJBnch"
   },
   "source": [
    "So far, we have 1 hour and 10 minutes of precipitation images, separated 2 minutes apart from each other.\n",
    "But, how do we use that data to run a precipitation forecast? \n",
    "\n",
    "A simple way is by extrapolating the precipitation field, assuming it will continue to move as observed in the recent past, and without changes in intensity. This is commonly known as *Lagrangian persistence*.\n",
    "\n",
    "The first step to run our nowcast based on Lagrangian persistence is the estimation of the motion field from a sequence of past precipitation observations. \n",
    "We use the Lucas-Kanade (LK) optical flow method implemented in pysteps.\n",
    "This method follows a local tracking approach that relies on the OpenCV package.\n",
    "Local features are tracked in a sequence of two or more radar images.\n",
    "The scheme includes a final interpolation step to produce a smooth field of motion vectors.\n",
    "Other optical flow methods are also available in pysteps. \n",
    "Check the full list [here](https://pysteps.readthedocs.io/en/latest/pysteps_reference/motion.html).\n",
    "\n",
    "Now let's use the first 5 precipitation images (10 min) to estimate the motion field of the radar pattern and the remaining 30 images (1h) to evaluate the quality of our forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcb2Sf6xBnck"
   },
   "outputs": [],
   "source": [
    "# precipitation[0:5] -> Used to find motion (past data). Let's call it training precip.\n",
    "train_precip = precipitation[0:5]\n",
    "\n",
    "# precipitation[5:] -> Used to evaluate forecasts (future data, not available in \"real\" forecast situation)\n",
    "# Let's call it observed precipitation because we will use it to compare our forecast with the actual observations.\n",
    "observed_precip = precipitation[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xt1TbB0RBncu"
   },
   "source": [
    "Let's see how this precipitation event looks like using the [pysteps.visualization.plot_precip_field](https://pysteps.readthedocs.io/en/latest/generated/pysteps.visualization.precipfields.plot_precip_field.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmNYLo1jBncw"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pysteps.visualization import plot_precip_field\n",
    "\n",
    "# Set the figure size that looks nice ;)\n",
    "plt.figure(figsize=(9, 5), dpi=100)\n",
    "\n",
    "# Plot the last rainfall field in the \"training\" data.\n",
    "# train_precip[-1] -> Last available composite for nowcasting.\n",
    "plot_precip_field(train_precip[-1], geodata=metadata, axis=\"off\", map=\"cartopy\")\n",
    "plt.show()  # (This line is not actually needed if you are using jupyter notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVRfJm11Bnc7"
   },
   "source": [
    "Did you note the **shaded grey** regions? Those are the regions were no valid observations where available to estimate the precipitation (e.g., due to ground clutter, no radar coverage, or radar beam blockage).\n",
    "Those regions need to be handle with care when we run our nowcast.\n",
    "\n",
    "### Data exploration\n",
    "\n",
    "Before we produce a forecast, let's explore precipitation data. In particular, let's see how the distribution of the rain rate values looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WER6RttPBnc9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's define some ploting default parameters for the next plots\n",
    "# Note: This is not strictly needed.\n",
    "plt.rc('figure', figsize=(4,4))\n",
    "plt.rc('figure', dpi=100)\n",
    "plt.rc('font', size=14) # controls default text sizes\n",
    "plt.rc('axes', titlesize=14) # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14) # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14) # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14) # fontsize of the tick labels\n",
    "\n",
    "# Let's use the last available composite for nowcasting from the \"training\" data (train_precip[-1])\n",
    "# Also, we will discard any invalid value.\n",
    "valid_precip_values = train_precip[-1][~np.isnan(train_precip[-1])]\n",
    "\n",
    "bins= np.concatenate( ([-0.01,0.01], np.linspace(1,40,39)))\n",
    "plt.hist(valid_precip_values,bins=bins,log=True, edgecolor='black')\n",
    "plt.autoscale(tight=True, axis='x')\n",
    "plt.xlabel(\"Rainrate [mm/h]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title('Precipitation rain rate histogram in mm/h units')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6TvIXS3BndH"
   },
   "source": [
    "The previous histogram shows that rain rate values have a non-Gaussian and asymmetric distribution that is bounded at zero. Also, the probability of occurrence decays extremely fast with increasing rain rate values (note the logarithmic y-axis).\n",
    "\n",
    "\n",
    "For better performance of the motion estimation algorithms, we can convert the rain rate values (in mm/h) to a more log-normal distribution  of rain rates by applying the following logarithmic transformation:\n",
    "\n",
    "\\begin{equation}\n",
    "R\\rightarrow\n",
    "\\begin{cases}\n",
    "    10\\log_{10}R, & \\text{if } R\\geq 0.1\\text{mm h$^{-1}$} \\\\\n",
    "    -15,          & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "The transformed precipitation corresponds to logarithmic rain rates in units of dBR. The value of −15 dBR is equivalent to assigning a rain rate of approximately 0.03 mm h$^{−1}$ to the zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgA4PeapBndK"
   },
   "outputs": [],
   "source": [
    "from pysteps.utils import transformation\n",
    "\n",
    "# Log-transform the data to dBR. \n",
    "#The threshold to 0.1 mm/h sets the fill value to -15 dBR.\n",
    "train_precip_dbr, metadata_dbr = transformation.dB_transform(train_precip, metadata, \n",
    "                                                             threshold=0.1, \n",
    "                                                             zerovalue=-15.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nx3VESBlBndU"
   },
   "source": [
    "Let's see how the **transformed precipitation** distribution looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYS5hBIGBndX"
   },
   "outputs": [],
   "source": [
    "# Only use the valid data!\n",
    "valid_precip_dbr = train_precip_dbr[-1][~np.isnan(train_precip_dbr[-1])]\n",
    "\n",
    "plt.figure(figsize=(4, 4), dpi=100)\n",
    "\n",
    "counts, bins, _ = plt.hist(valid_precip_dbr, bins=40, log=True, edgecolor=\"black\")\n",
    "plt.autoscale(tight=True, axis=\"x\")\n",
    "plt.xlabel(\"Rainrate [dB]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Precipitation rain rate histogram in dB units\")\n",
    "\n",
    "# Let's add to the plot a lognormal distribution that fits that data.\n",
    "import scipy\n",
    "\n",
    "bin_center = (bins[1:] + bins[:-1]) * 0.5\n",
    "bin_width = np.diff(bins)\n",
    "\n",
    "# We will use only one composite for to fit function to speed up things.\n",
    "precip_to_fit = valid_precip_dbr[valid_precip_dbr > -15]  # Remove the no precip areas.\n",
    "\n",
    "fit_params = scipy.stats.lognorm.fit(precip_to_fit)\n",
    "\n",
    "fitted_pdf = scipy.stats.lognorm.pdf(bin_center, *fit_params)\n",
    "# Multiply pdf by the bin width and the total number of grid points: pdf -> total counts per bin.\n",
    "fitted_pdf = fitted_pdf * bin_width * precip_to_fit.size\n",
    "\n",
    "plt.plot(bin_center, fitted_pdf, label=\"Fitted log-normal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZocO5zqUBndg"
   },
   "source": [
    "That looks more like a log-normal distribution. Note the large peak at -15dB. That peak corresponds to the \"zero\" (below threshold) precipitation. \n",
    "\n",
    "## Compute the nowcast\n",
    "\n",
    "These are the minimal steps to compute a short-term forecast using lagrangian extrapolation of the precipitation patterns:\n",
    " \n",
    " 1. Estimate the precipitation motion field.\n",
    " 1. The motion field to advect the most recent radar rainfall field and produce an extrapolation forecast.\n",
    "\n",
    "But before, \n",
    "\n",
    "### Estimate the motion field\n",
    "\n",
    "Now we can estimate the motion field. Here we use a local feature-tracking approach (Lucas-Kanade).\n",
    "However, check the other methods available in the [pysteps.motion](https://pysteps.readthedocs.io/en/latest/pysteps_reference/motion.html) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnACmX_0Bndi"
   },
   "outputs": [],
   "source": [
    "# Estimate the motion field with Lucas-Kanade\n",
    "from pysteps import motion\n",
    "from pysteps.visualization import plot_precip_field, quiver\n",
    "\n",
    "oflow_method = motion.get_method(\"LK\")\n",
    "motion_field = oflow_method(train_precip_dbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgFTrnKTBndu"
   },
   "outputs": [],
   "source": [
    "## Plot the motion field.\n",
    "# Set the figure size that looks nice ;)\n",
    "plt.figure(figsize=(9, 5), dpi=100)\n",
    "\n",
    "# Plot the last rainfall field in the \"training\" data.\n",
    "# Remember to use the mm/h precipitation data since plot_precip_field assumes mm/h by default.\n",
    "# You can change this behavior using the \"units\" keyword.\n",
    "plot_precip_field(train_precip[-1], geodata=metadata, axis=\"off\")\n",
    "quiver(motion_field, geodata=metadata, step=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YObddRFCBnd1"
   },
   "source": [
    "### Extrapolate the observations\n",
    "\n",
    "The final step is to advect the most recent radar rainfall field along the estimated motion field, producing an extrapolation forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erSLAzvNBnd3"
   },
   "outputs": [],
   "source": [
    "from pysteps import nowcasts\n",
    "\n",
    "# Extrapolate the last radar observation\n",
    "extrapolate = nowcasts.get_method(\"extrapolation\")\n",
    "\n",
    "# You can use the precipitation observations directly in mm/h for this step.\n",
    "last_observation = train_precip[-1]\n",
    "\n",
    "last_observation[~np.isfinite(last_observation)] = metadata[\"zerovalue\"]\n",
    "\n",
    "n_leadtimes = observed_precip.shape[0]\n",
    "precip_forecast = extrapolate(train_precip[-1], motion_field, n_leadtimes)\n",
    "\n",
    "precip_forecast.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csy5s-yRBneB"
   },
   "source": [
    "Let's see how the last forecast time looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUiS5-HPBneD"
   },
   "outputs": [],
   "source": [
    "# Plot precipitation at the end of the forecast period.\n",
    "plt.figure(figsize=(9, 5), dpi=100)\n",
    "plot_precip_field(precip_forecast[-1], geodata=metadata, axis=\"off\", map='cartopy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mQEseXvhBneI"
   },
   "source": [
    "### Evaluate the forecast quality\n",
    "\n",
    "The Fractions Skill Score (FSS) provides an intuitive assessment of the dependency of skill on spatial scale and intensity. This makes the FSS an ideal skill score for high-resolution precipitation forecasts.\n",
    "\n",
    "More precisely, the FSS is a neighborhood spatial verification method that directly compares the fractional coverage of events in windows surrounding the observations and forecasts.\n",
    "The FSS varies from 0 (total mismatch) to 1 (perfect forecast).\n",
    "For most situations, an FSS value of >0.5 serves as a good indicator of a useful forecast ([Skok and Roberts, 2016](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.2849)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "No3qBjqSBneK"
   },
   "outputs": [],
   "source": [
    "from pysteps import verification\n",
    "\n",
    "fss = verification.get_method(\"FSS\")\n",
    "\n",
    "# Compute fractions skill score (FSS) for all lead times for different scales using a 1 mm/h detection threshold.\n",
    "scales = [\n",
    "    2,\n",
    "    4,\n",
    "    8,\n",
    "    16,\n",
    "    32,\n",
    "    64,\n",
    "]  # In grid points.\n",
    "\n",
    "scales_in_km = np.array(scales)*4\n",
    "\n",
    "thr = 1.0  # in mm/h\n",
    "score = []\n",
    "for i in range(n_leadtimes):\n",
    "    score_ = []\n",
    "    for scale in scales:\n",
    "        score_.append(\n",
    "            fss(precip_forecast[i, :, :], observed_precip[i, :, :], thr, scale)\n",
    "        )\n",
    "    score.append(score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JX6kLNoLBneR"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = np.arange(1, n_leadtimes+1) * timestep\n",
    "plt.plot(x, score, lw=2.0)\n",
    "plt.xlabel(\"Lead time [min]\")\n",
    "plt.ylabel(\"FSS ( > 1.0 mm/h ) \")\n",
    "plt.title(\"Fractions Skill Score\")\n",
    "plt.legend(\n",
    "    scales_in_km, \n",
    "    title=\"Scale [km]\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.01, 0.5),\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    ")\n",
    "plt.autoscale(axis=\"x\", tight=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lwsOklbV8E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "my_first_nowcast.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
